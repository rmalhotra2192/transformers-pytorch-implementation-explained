# transformers-pytorch-implementation-explained
This notebook is my attempt in order to better understand the **implementation of Transformers ( Based on the famous paper "[Attention is all you need](https://arxiv.org/abs/1706.03762)") from scratch in PyTorch**. 

I have added extensive comments in order to decode most of the code and relate what it's doing relative to the architecture that's explained in the paper and how it's being trained. Hope it helps you.
